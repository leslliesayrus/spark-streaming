{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace68fc3-0bb9-4457-8910-6800590f5292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col, current_timestamp, to_json, struct,  expr\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78e40599-caa4-4784-9a97-84ae49d01c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder. \\\n",
    "        config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538635b5-c644-4160-aa4f-83cad1bb3b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"driver_id\", IntegerType(), True),\n",
    "    StructField(\"source\", StringType(), True),\n",
    "    StructField(\"destination\", StringType(), True),\n",
    "    StructField(\"price\", DoubleType(), True),\n",
    "    StructField(\"time_traveled\", DoubleType(), True),\n",
    "    StructField(\"distance_traveled\", DoubleType(), True),\n",
    "    StructField(\"uber_black\", IntegerType(), True),\n",
    "    StructField(\"time_message\", TimestampType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8919237f-401e-4883-9a6a-c0581e122e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_read = \"topic-ingestion\"\n",
    "ip_kafka = \"192.168.1.6:9092\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d15d509-204e-45e2-83e5-28cb3df1bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rides = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", ip_kafka) \\\n",
    "  .option(\"subscribe\", topic_read) \\\n",
    "  .load() \\\n",
    "  .select(from_json(col(\"value\").cast(\"string\"), schema).alias(\"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d90fd11-eca7-4978-9011-91e5d2f0e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rides.createOrReplaceTempView(\"df_rides\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34212b68-5ea9-459b-a4bd-d41add8773c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30055"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_driver = spark.read.parquet(\"/home/jovyan/work/lake/drivers\")\n",
    "df_driver.createOrReplaceTempView(\"df_driver\")\n",
    "df_driver.cache()\n",
    "df_driver.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "013f2264-3f7e-4546-91a6-6ee3c8120d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---+----------------+----+\n",
      "| id|                name|age|             car|rate|\n",
      "+---+--------------------+---+----------------+----+\n",
      "|  1|John Hernandez Me...| 42|Chevrolet Blazer|4.51|\n",
      "|  2|Haley Patterson H...| 59|Volkswagen Atlas|4.48|\n",
      "|  3|  Jill Burke Stewart| 40|    BMW 3 Series|4.53|\n",
      "|  4|    Maria Lewis Bass| 21|Dodge Challenger|4.55|\n",
      "|  5|  Austin Miles Drake| 36|    Nissan Versa|4.46|\n",
      "+---+--------------------+---+----------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_driver.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "086102c3-007b-4d40-bffa-cbaa3c8bb319",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rides_01 = spark.sql(\"\"\"\n",
    "\n",
    "    select\n",
    "        a.data.id as id,\n",
    "        a.data.user_id as user_id,\n",
    "        a.data.driver_id as driver_id,\n",
    "        a.data.source as source,\n",
    "        a.data.destination as destination,\n",
    "        a.data.price as price,\n",
    "        a.data.time_traveled as time_traveled,\n",
    "        a.data.distance_traveled as distance_traveled,\n",
    "        a.data.uber_black as uber_black,\n",
    "        a.data.time_message as time_message,\n",
    "\n",
    "        case when a.data.uber_black = 1 then round(a.data.price * 0.20 ,2)\n",
    "            else round(a.data.price * 0.25,2) end as rate\n",
    "        \n",
    "    from\n",
    "        df_rides a\n",
    "        \"\"\")\n",
    "\n",
    "\n",
    "df_rides_01.createOrReplaceTempView(\"df_rides_01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71a54914-c7d7-49d6-9831-bca0d5636a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rides_02 = spark.sql(\"\"\"\n",
    "    select\n",
    "        a.id as id,\n",
    "        b.name as driver_name,\n",
    "        a.user_id,\n",
    "        a.source as source,\n",
    "        a.destination as destination,\n",
    "        a.price as price,\n",
    "        a.time_traveled as time_traveled,\n",
    "        a.distance_traveled as distance_traveled,\n",
    "        a.uber_black as uber_black,\n",
    "        a.time_message as time_message,\n",
    "        a.rate\n",
    "\n",
    "    from\n",
    "        df_rides_01 a\n",
    "    left join\n",
    "        df_driver b\n",
    "    on (a.driver_id = b.id)\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "df_rides_02.createOrReplaceTempView(\"df_rides_02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "034e7b02-e42e-4927-88ba-62c116d4366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_write = \"topic-processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41dab27-6ad1-45c7-979d-eff5b18ce0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_col = expr(\"struct(id, driver_name, user_id, source, destination, price, time_traveled, distance_traveled, rate, uber_black, time_message) as data\")\n",
    "\n",
    "# Adicione uma coluna JSON contendo todas as informações\n",
    "json_df = df_rides_02.select(to_json(struct_col).alias(\"value\"))\n",
    "\n",
    "query = (\n",
    "    json_df\n",
    "    .writeStream\n",
    "    .outputMode(\"append\")\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", ip_kafka) \n",
    "    .option(\"topic\", topic_write) \n",
    "    .option(\"checkpointLocation\", \"/home/jovyan/work/lake/checkpoint\")\n",
    "    .start()\n",
    ")\n",
    "\n",
    "# Aguarde a conclusão do streaming\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f569892-155c-430c-8081-949d019b59a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e4bfa-e838-4be6-8de9-a256b868f973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d3e58-324c-471a-b667-d25382ca9891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24956e22-fdcd-460e-b914-f522bf4c1e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c75140-9323-488c-aff8-9f515c37560d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0ecb9-a7e7-492c-8dbb-8fd8851b14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    df_rides_02\n",
    "    .writeStream\n",
    "    .outputMode(\"append\")\n",
    "    .format(\"console\")\n",
    "    .option(\"checkpointLocation\", \"checkpoint\")  # Adicione esta linha\n",
    "    .start()\n",
    ")\n",
    "\n",
    "# Aguarde a consulta ser encerrada\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1872611b-04d5-425b-ac78-ccfc74f53c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b2f3ca-b247-452e-99d6-96bb9906c60c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_rides_schema = StructType([\n",
    "  StructField(\"id\", IntegerType()),\n",
    "  StructField(\"travel_time\", IntegerType()),\n",
    "  StructField(\"distance\", FloatType()),\n",
    "  StructField(\"mode\", StringType())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "df_rides = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"192.168.1.6:9092\") \\\n",
    "  .option(\"subscribe\", \"topic-data\") \\\n",
    "  .load() \\\n",
    "  .select(from_json(col(\"value\").cast(\"string\"), df_rides_schema).alias(\"data\"))\n",
    "\n",
    "df_rides.createOrReplaceTempView(\"df_rides\")\n",
    "\n",
    "df_rides_01 = spark.sql(\"\"\"\n",
    "\n",
    "    select\n",
    "        a.data.id as id,\n",
    "        a.data.travel_time as travel_time,\n",
    "        a.data.distance as distance,\n",
    "        case when a.data.mode = 'UberX' then 1 else 0 end as dummy_uberx,\n",
    "        case when a.data.mode = 'UberConfort' then 1 else 0 end as dummy_uberconfort\n",
    "        \n",
    "    from\n",
    "        df_rides a\n",
    "        \"\"\")\n",
    "\n",
    "# query = df_rides_01.writeStream \\\n",
    "#     .outputMode(\"append\") \\\n",
    "#     .format(\"console\") \\\n",
    "#     .start()\n",
    "\n",
    "# # Aguarda o término da execução\n",
    "# query.awaitTermination()\n",
    "\n",
    "outputDF = df_rides_01.select(to_json(struct(\"*\")).alias(\"value\"))\n",
    "#transformed_df = outputDF.selectExpr(\"value\")\n",
    "transformed_df = df_rides_01\n",
    "# kafkaOptions = {\n",
    "#   \"kafka.bootstrap.servers\": \"192.168.1.6:9092\",\n",
    "#   \"topic\": \"topic-data-for-model\",\n",
    "#   \"value.serializer\": \"org.apache.kafka.common.serialization.StringSerializer\"\n",
    "# }\n",
    "\n",
    "# outputDF.writeStream \\\n",
    "#     .format(\"kafka\") \\\n",
    "#     .option(\"checkpointLocation\", \"/home/jovyan/work/checkpoint\") \\\n",
    "#     .options(**kafkaOptions) \\\n",
    "#     .start().awaitTermination()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7812e1-2067-4502-80b1-632847cac4b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# query = (\n",
    "#     outputDF\n",
    "#     .writeStream\n",
    "#     .outputMode(\"append\")  # Pode ser \"append\", \"complete\" ou \"update\" dependendo do seu caso\n",
    "#     .format(\"console\")\n",
    "#     .start()\n",
    "# )\n",
    "\n",
    "struct_col = expr(\"struct(id, travel_time, distance, dummy_uberx, dummy_uberconfort) as data\")\n",
    "\n",
    "# Adicione uma coluna JSON contendo todas as informações\n",
    "json_df = df_rides_01.select(to_json(struct_col).alias(\"value\"))\n",
    "\n",
    "query = (\n",
    "    json_df\n",
    "    .writeStream\n",
    "    .outputMode(\"append\")  # Pode ser \"append\", \"complete\" ou \"update\" dependendo do seu caso\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"192.168.1.6:9092\")  # Endereço do servidor Kafka\n",
    "    .option(\"topic\", \"topic-gold\")  # Tópico Kafka de saída\n",
    "    .option(\"checkpointLocation\", \"checkpoint\")  # Diretório para armazenar checkpoints\n",
    "    .start()\n",
    ")\n",
    "\n",
    "# Aguarde a conclusão do streaming\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437fed97-60b1-4388-a141-c7beb395fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce3875-383f-4b62-921e-f40e5015325d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fe9786-c786-450d-a8f4-14357749798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT data.zone, SUM(data.time) as total_time FROM df_zone GROUP BY 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8c74cb-436b-405e-bbe4-4d15ef772182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zone_02.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56f8e0f-c158-4972-8363-682277f5f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rides_demand.withWatermark(\"timestamp\", \"1 minute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb27c75-4142-4f6e-b799-6c931e80552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d05dd6-e62b-4af5-b22d-901ab8c375eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
